{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h1>OpenCV Basics for Image Preprocessing</h1>\n",
    "<h3>1. Reading and Displaying Images</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.imread(), cv2.imshow(), cv2.imwrite()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Reading images is fundamental before applying any transformations. Displaying allows verification, and saving is useful for storing results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('test_image.jpg')\n",
    "# Naming a window \n",
    "cv2.namedWindow(\"Original Image\", cv2.WINDOW_NORMAL) \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"Original Image\", 1280, 720) \n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h3>2. Converting Color Spaces</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.cvtColor()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Converting images to grayscale or other color spaces (like HSV) is essential for various algorithms that work with simpler or specific color spaces.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # cv2.COLOR_BGR2HSV \n",
    "# Naming a window \n",
    "cv2.namedWindow(\"Grayscale Image\", cv2.WINDOW_NORMAL) \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"Grayscale Image\", 1280, 720) \n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Split the image into its color channels\n",
    "b_channel, g_channel, r_channel = cv2.split(image)\n",
    "\n",
    "# Create a black image for each channel\n",
    "height, width, channel = image.shape\n",
    "black_image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# Create an image for each channel\n",
    "red_image = cv2.merge([black_image, black_image, r_channel])\n",
    "green_image = cv2.merge([black_image, g_channel, black_image])\n",
    "blue_image = cv2.merge([b_channel, black_image, black_image])\n",
    "\n",
    "# Stack the images horizontally\n",
    "combined_image = np.hstack((blue_image, green_image, red_image))\n",
    "\n",
    "# Naming a window \n",
    "cv2.namedWindow(\"Combined Color Channels\", cv2.WINDOW_NORMAL) \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"Combined Color Channels\", 1280, 720) \n",
    "\n",
    "# Display the combined image\n",
    "cv2.imshow('Combined Color Channels', combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h3>3. Resizing Images</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.resize()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Resizing is crucial to standardize input dimensions for deep learning models and reduce computational load.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curren Image dimension: (1406, 2131, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Curren Image dimension:\", image.shape)\n",
    "resized_image = cv2.resize(image, (1280, 720))\n",
    "cv2.imwrite(\"resized_image.jpg\", resized_image)\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h3>4. Blurring and Smoothing</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.GaussianBlur()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Smoothing or blurring helps reduce image noise, making edge detection and other tasks more effective.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = cv2.GaussianBlur(resized_image, (17, 17), 100)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h3>5. Edge Detection</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.Canny()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Detecting edges is foundational for object detection and shape analysis, often used to highlight structural elements.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray_image, 150, 200)\n",
    "# Naming a window \n",
    "cv2.namedWindow(\"Edge Detected Image\", cv2.WINDOW_NORMAL) \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"Edge Detected Image\", 1280, 720) \n",
    "cv2.imshow('Edge Detected Image', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"BBox\" class=\"alert alert-warning\" style=\"font-family:courier;color:black;justify-content:left;\">\n",
    "<h3>6. Image Thresholding</h3>\n",
    "<strong>Method: </strong>\n",
    "cv2.threshold()\n",
    "<br><br>\n",
    "<strong>Explanation: </strong>\n",
    "Thresholding is used to segment images by converting them to binary, facilitating object detection and image analysis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "# Naming a window \n",
    "cv2.namedWindow(\"Binary Image\", cv2.WINDOW_NORMAL) \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"Binary Image\", 1280, 720)\n",
    "cv2.imshow('Binary Image', binary_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
